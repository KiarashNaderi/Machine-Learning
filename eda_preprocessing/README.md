# 🧠 EDA & Data Preprocessing 

A complete, block-based Jupyter Notebook that demonstrates a full real-world preprocessing workflow on customer data — from raw CSV to clean, model-ready format.

📌 Dataset: [Telco Customer Churn – Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)

---

## 🎯 Objective

This notebook implements a robust and scalable preprocessing pipeline for real-world tabular data. It includes every critical step in preparing data for predictive modeling, with clean structure and professional documentation.

---

## 🧱 Notebook Structure
📘 full_eda_preprocessing.ipynb
📝 README.md

All steps are implemented in a single notebook with clearly separated chapters:

| Chapter | Description |
|--------|-------------------------------|
| 0 | Introduction |
| 1 | Data Loading & Initial Exploration |
| 2 | Data Cleaning & Missing Values |
| 3 | Exploratory Data Analysis (EDA) |
| 4 | Categorical Encoding & Feature Scaling |
| 5 | Feature Engineering |
| 6 | Data Splitting & Final Preparation |

---

## 🧪 Dataset Overview

- Dataset: Telco Customer Churn  
- Type: Binary Classification  
- Features: Numerical, Categorical, and Text  
- Contains: Missing values, data type issues, imbalanced target variable

---

## ⚙️ Technologies Used

## ⚙️ Technologies Used

- Python 3.10+
- Jupyter Notebook
- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn
- imbalanced-learn
- missingno (optional)

---

## 🔍 Highlights

- Real-world cleaning of object-based numeric fields
- Handling missing values with logic-based decisions
- Visualization-driven EDA and outlier analysis
- Balanced encoding and feature scaling strategies
- Modular, reusable structure for ML projects

---

## 🚀 How to Use

1. Download the dataset from Kaggle.
2. Place the CSV file in the same directory as the notebook.
3. Run `full_course_eda_preprocessing.ipynb` step by step.
4. Use it as a template or base pipeline in your ML workflows.

---

