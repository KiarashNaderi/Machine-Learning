# ğŸ§  EDA & Data Preprocessing 

A complete, block-based Jupyter Notebook that demonstrates a full real-world preprocessing workflow on customer data â€” from raw CSV to clean, model-ready format.

ğŸ“Œ Dataset: [Telco Customer Churn â€“ Kaggle](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)

---

## ğŸ¯ Objective

This notebook implements a robust and scalable preprocessing pipeline for real-world tabular data. It includes every critical step in preparing data for predictive modeling, with clean structure and professional documentation.

---

## ğŸ§± Notebook Structure
ğŸ“˜ full_eda_preprocessing.ipynb
ğŸ“ README.md

All steps are implemented in a single notebook with clearly separated chapters:

| Chapter | Description |
|--------|-------------------------------|
| 0 | Introduction |
| 1 | Data Loading & Initial Exploration |
| 2 | Data Cleaning & Missing Values |
| 3 | Exploratory Data Analysis (EDA) |
| 4 | Categorical Encoding & Feature Scaling |
| 5 | Feature Engineering |
| 6 | Data Splitting & Final Preparation |

---

## ğŸ§ª Dataset Overview

- Dataset: Telco Customer Churn  
- Type: Binary Classification  
- Features: Numerical, Categorical, and Text  
- Contains: Missing values, data type issues, imbalanced target variable

---

## âš™ï¸ Technologies Used

## âš™ï¸ Technologies Used

- Python 3.10+
- Jupyter Notebook
- pandas
- numpy
- matplotlib
- seaborn
- scikit-learn
- imbalanced-learn
- missingno (optional)

---

## ğŸ” Highlights

- Real-world cleaning of object-based numeric fields
- Handling missing values with logic-based decisions
- Visualization-driven EDA and outlier analysis
- Balanced encoding and feature scaling strategies
- Modular, reusable structure for ML projects

---

## ğŸš€ How to Use

1. Download the dataset from Kaggle.
2. Place the CSV file in the same directory as the notebook.
3. Run `full_course_eda_preprocessing.ipynb` step by step.
4. Use it as a template or base pipeline in your ML workflows.

---

